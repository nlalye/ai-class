{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca22115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# MNIST DIGIT CLASSIFIER (PyTorch)\n",
    "# -----------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn #neural network superclass\n",
    "from torchvision import datasets, transforms #gives ready to use datasets and preprocessing tools\n",
    "import torch.optim as optim #imports optimization algorithms from torch\n",
    "from torch.utils.data import DataLoader #streamlines process of loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2a9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. LOAD DATA\n",
    "# Transforms are preprocessing steps that get applied automatically to every image you load from a dataset. \n",
    "# Think of transforms as a recipe that says:\n",
    "\n",
    "# “Every time you give me an image, do X, then Y, then Z to it.”\n",
    "# “For every MNIST image: convert it to a PyTorch tensor.\n",
    "# MNIST images come in as PIL images (Python Imaging Library).\n",
    "\n",
    "# But your neural network expects tensors.\n",
    "# -----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abf5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset (MNIST)\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de572723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87def014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# Make DataLoaders (create loaders that give batches of data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) #increasing batch size speeds up training process\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# TODO: Access and print the unique labels in the training data set using the train_loader object\n",
    "labels = set() #stores unique items and removes duplicates\n",
    "\n",
    "for batch in train_loader:\n",
    "    _, targets = batch #ignores data with _ because we just need labels\n",
    "    for t in targets: # loop through labels\n",
    "        labels.add(int(t))\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091eb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. DEFINE NEURAL NETWORK\n",
    "# TODO: Neural Network with 2 hidden layers of 128 neurons\n",
    "# -----------------------------\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: Define layers (784 inputs from 28 * 28)\n",
    "        self.fc1 = nn.Linear(784, 128) #1st hidden layer\n",
    "        self.fc2 = nn.Linear(128, 128) #2nd hidden layer\n",
    "        self.fc3 = nn.Linear(128, 10) #10 outputs from 0-9\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten image: (batch, 1, 28, 28) → (batch, 784)\n",
    "        x = x.view(-1, 28*28)\n",
    "\n",
    "        # TODO: Add activation between layers\n",
    "        x = torch.relu(self.fc1(x)) #outputs input if positive, 0 if negative\n",
    "        x = torch.relu(self.fc2(x))\n",
    "\n",
    "        # TODO: Output layer\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138089f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the model\n",
    "\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d12046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. LOSS FUNCTION + OPTIMIZER\n",
    "# -----------------------------\n",
    "# TODO: Define your loss function\n",
    "criterion = nn.CrossEntropyLoss() # loss for classification tasks\n",
    "\n",
    "# TODO: Setup your gradient descent . Try different values for the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum = 0.9) #Stochastic Gradient Descent\n",
    "# learning rate = size of step, momentum adds inertia (smooths out oscillations)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32ff29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 321.4670\n",
      "Epoch 2, Loss: 109.2142\n",
      "Epoch 3, Loss: 74.2942\n",
      "Epoch 4, Loss: 53.7998\n",
      "Epoch 5, Loss: 44.4435\n",
      "Epoch 6, Loss: 35.0250\n",
      "Epoch 7, Loss: 27.9654\n",
      "Epoch 8, Loss: 23.1732\n",
      "Epoch 9, Loss: 19.1767\n",
      "Epoch 10, Loss: 16.5698\n",
      "Epoch 11, Loss: 11.3132\n",
      "Epoch 12, Loss: 7.5828\n",
      "Epoch 13, Loss: 7.0057\n",
      "Epoch 14, Loss: 5.8395\n",
      "Epoch 15, Loss: 6.8501\n",
      "Epoch 16, Loss: 2.3408\n",
      "Epoch 17, Loss: 1.0345\n",
      "Epoch 18, Loss: 0.5207\n",
      "Epoch 19, Loss: 0.3677\n",
      "Epoch 20, Loss: 0.2868\n",
      "Epoch 21, Loss: 0.2483\n",
      "Epoch 22, Loss: 0.2177\n",
      "Epoch 23, Loss: 0.1953\n",
      "Epoch 24, Loss: 0.1814\n",
      "Epoch 25, Loss: 0.1656\n",
      "Epoch 26, Loss: 0.1535\n",
      "Epoch 27, Loss: 0.1451\n",
      "Epoch 28, Loss: 0.1361\n",
      "Epoch 29, Loss: 0.1296\n",
      "Epoch 30, Loss: 0.1230\n",
      "Epoch 31, Loss: 0.1160\n",
      "Epoch 32, Loss: 0.1111\n",
      "Epoch 33, Loss: 0.1065\n",
      "Epoch 34, Loss: 0.1022\n",
      "Epoch 35, Loss: 0.0980\n",
      "Epoch 36, Loss: 0.0942\n",
      "Epoch 37, Loss: 0.0906\n",
      "Epoch 38, Loss: 0.0875\n",
      "Epoch 39, Loss: 0.0842\n",
      "Epoch 40, Loss: 0.0818\n",
      "Epoch 41, Loss: 0.0790\n",
      "Epoch 42, Loss: 0.0765\n",
      "Epoch 43, Loss: 0.0743\n",
      "Epoch 44, Loss: 0.0719\n",
      "Epoch 45, Loss: 0.0700\n",
      "Epoch 46, Loss: 0.0680\n",
      "Epoch 47, Loss: 0.0662\n",
      "Epoch 48, Loss: 0.0644\n",
      "Epoch 49, Loss: 0.0630\n",
      "Epoch 50, Loss: 0.0614\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. TRAINING LOOP\n",
    "# -----------------------------\n",
    "\n",
    "# TODO: Define the number of epochs\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # TODO: Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # TODO: Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # TODO: Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # TODO: Update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() #converts loss from a tensor into a python number (add every batch's loss to total loss for epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c6e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.48%\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. EVALUATION\n",
    "# -----------------------------\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(): #faster with no gradient\n",
    "    for images, labels in test_loader:\n",
    "        # TODO: Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Predicted class = index of max logit\n",
    "        _, predicted = torch.max(outputs.data, 1) #finds index of the highest score for each image (predicted stores class indices, __ stores max values)\n",
    "\n",
    "        total += labels.size(0) #counts how many images were tested\n",
    "        correct += (predicted == labels).sum().item() #number of correct predictions in batch\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cb85dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr #interactive web-demo library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b038ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. TEST SINGLE PREDICTION\n",
    "# ------------------------------\n",
    "# Gradio Sketchpad gives you:\n",
    "\n",
    "# * a full-color NumPy array\n",
    "\n",
    "# * black digit on white background\n",
    "\n",
    "# * large resolution\n",
    "\n",
    "# * no consistent scale\n",
    "#\n",
    "# Hence the preprocessing\n",
    "# ------------------------------\n",
    "\n",
    "def preprocess_image(image):\n",
    "    sketch_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                      # NumPy → PIL\n",
    "    transforms.Grayscale(),                       # ensure 1 channel\n",
    "    transforms.Resize((28, 28)),                  # 28x28 like MNIST\n",
    "    transforms.Lambda(lambda img: ImageOps.invert(img)),  # invert colors\n",
    "    transforms.ToTensor(),                        # → tensor, shape (1,28,28), values in [0,1]\n",
    "    ])\n",
    "    # Gradio Sketchpad sometimes passes a dict with 'composite'\n",
    "    if isinstance(image, dict):\n",
    "        image = image['composite']   # this is a NumPy array\n",
    "    \n",
    "    # Apply the preprocessing transform\n",
    "    img_tensor = sketch_transform(image)  # (1, 28, 28)\n",
    "    \n",
    "    # Add batch dimension → (1, 1, 28, 28)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def predict_digit(image):\n",
    "    # --- STEP 1: CHECK IF SOMETHING HAS BEEN DRAWN ---\n",
    "    if image is None: return \"Draw something!\"\n",
    "\n",
    "    # --- STEP 2: PREPROCESS THE IMAGE ---\n",
    "    img_tensor = preprocess_image(image)\n",
    "    \n",
    "    # --- STEP 3: RUN THE MODEL ---\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img_tensor)\n",
    "        \n",
    "        # Get the index of the highest score (the predicted digit)\n",
    "        predicted_digit = torch.argmax(prediction).item()\n",
    "        \n",
    "    return str(predicted_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257bc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps #Pillow library that allows you to open, manipulate, and process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "606eb64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=predict_digit,\n",
    "    inputs=gr.Sketchpad(type=\"numpy\", label=\"Draw a digit\"),\n",
    "    outputs=gr.Label(num_top_classes=1),\n",
    "    live=False\n",
    ")\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
