{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cca22115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# MNIST DIGIT CLASSIFIER (PyTorch)\n",
    "# -----------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms #gives ready to use datasets and preprocessing tools\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df2a9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. LOAD DATA\n",
    "# Transforms are preprocessing steps that get applied automatically to every image you load from a dataset. \n",
    "# Think of transforms as a recipe that says:\n",
    "\n",
    "# “Every time you give me an image, do X, then Y, then Z to it.”\n",
    "# “For every MNIST image: convert it to a PyTorch tensor.\n",
    "# MNIST images come in as PIL images (Python Imaging Library).\n",
    "\n",
    "# But your neural network expects tensors.\n",
    "# -----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7abf5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset (MNIST)\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de572723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87def014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# Make DataLoaders (create loaders that give batches of data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# TODO: Access and print the unique labels in the training data set using the train_loader object\n",
    "labels = set() #stores unique items and removes duplicates\n",
    "\n",
    "for batch in train_loader:\n",
    "    _, targets = batch #ignores data with _ because we just need labels\n",
    "    for t in targets: # loop through labels\n",
    "        labels.add(int(t))\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "091eb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. DEFINE NEURAL NETWORK\n",
    "# TODO: Neural Network with 2 hidden layers of 128 neurons\n",
    "# -----------------------------\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: Define layers (784 inputs from 28 * 28)\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 10) #10 outputs from 0-9\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten image: (batch, 1, 28, 28) → (batch, 784)\n",
    "        x = x.view(-1, 28*28)\n",
    "\n",
    "        # TODO: Add activation between layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "\n",
    "        # TODO: Output layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "138089f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the model\n",
    "\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95d12046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. LOSS FUNCTION + OPTIMIZER\n",
    "# -----------------------------\n",
    "# TODO: Define your loss function\n",
    "criterion = nn.CrossEntropyLoss() # loss for classification tasks\n",
    "\n",
    "\n",
    "# TODO: Setup your gradient descent . Try different values for the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum = 0.9) #Stochastic Gradient Descent\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d32ff29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 307.7780\n",
      "Epoch 2, Loss: 128.6531\n",
      "Epoch 3, Loss: 90.4299\n",
      "Epoch 4, Loss: 70.4918\n",
      "Epoch 5, Loss: 55.8431\n",
      "Epoch 6, Loss: 45.9945\n",
      "Epoch 7, Loss: 38.3120\n",
      "Epoch 8, Loss: 32.8772\n",
      "Epoch 9, Loss: 26.4411\n",
      "Epoch 10, Loss: 22.8571\n",
      "Epoch 11, Loss: 18.8671\n",
      "Epoch 12, Loss: 15.5856\n",
      "Epoch 13, Loss: 12.6681\n",
      "Epoch 14, Loss: 10.5471\n",
      "Epoch 15, Loss: 8.6956\n",
      "Epoch 16, Loss: 7.6005\n",
      "Epoch 17, Loss: 5.9793\n",
      "Epoch 18, Loss: 5.1192\n",
      "Epoch 19, Loss: 4.2955\n",
      "Epoch 20, Loss: 3.8095\n",
      "Epoch 21, Loss: 3.2159\n",
      "Epoch 22, Loss: 2.6670\n",
      "Epoch 23, Loss: 2.4772\n",
      "Epoch 24, Loss: 2.2865\n",
      "Epoch 25, Loss: 2.0341\n",
      "Epoch 26, Loss: 1.8572\n",
      "Epoch 27, Loss: 1.7476\n",
      "Epoch 28, Loss: 1.6216\n",
      "Epoch 29, Loss: 1.5366\n",
      "Epoch 30, Loss: 1.4399\n",
      "Epoch 31, Loss: 1.3555\n",
      "Epoch 32, Loss: 1.2770\n",
      "Epoch 33, Loss: 1.2212\n",
      "Epoch 34, Loss: 1.1731\n",
      "Epoch 35, Loss: 1.1112\n",
      "Epoch 36, Loss: 1.0658\n",
      "Epoch 37, Loss: 1.0131\n",
      "Epoch 38, Loss: 0.9805\n",
      "Epoch 39, Loss: 0.9399\n",
      "Epoch 40, Loss: 0.9074\n",
      "Epoch 41, Loss: 0.8723\n",
      "Epoch 42, Loss: 0.8389\n",
      "Epoch 43, Loss: 0.8116\n",
      "Epoch 44, Loss: 0.7788\n",
      "Epoch 45, Loss: 0.7652\n",
      "Epoch 46, Loss: 0.7353\n",
      "Epoch 47, Loss: 0.7186\n",
      "Epoch 48, Loss: 0.6940\n",
      "Epoch 49, Loss: 0.6742\n",
      "Epoch 50, Loss: 0.6527\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. TRAINING LOOP\n",
    "# -----------------------------\n",
    "\n",
    "# TODO: Define the number of epochs\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # TODO: Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # TODO: Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # TODO: Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        # TODO: Update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() #converts loss from a tensor into a python number (add every batch's loss to total loss for epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59c6e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.11%\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. EVALUATION\n",
    "# -----------------------------\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(): #faster with no gradient\n",
    "    for images, labels in test_loader:\n",
    "        # TODO: Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Predicted class = index of max logit\n",
    "        _, predicted = torch.max(outputs.data, 1) #finds index of the highest score for each image (predicted stores class indices, __ stores max values)\n",
    "\n",
    "        total += labels.size(0) #counts how many images were tested\n",
    "        correct += (predicted == labels).sum().item() #number of correct predictions in batch\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cb85dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b038ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. TEST SINGLE PREDICTION\n",
    "# ------------------------------\n",
    "# Gradio Sketchpad gives you:\n",
    "\n",
    "# * a full-color NumPy array\n",
    "\n",
    "# * black digit on white background\n",
    "\n",
    "# * large resolution\n",
    "\n",
    "# * no consistent scale\n",
    "#\n",
    "# Hence the preprocessing\n",
    "# ------------------------------\n",
    "\n",
    "def preprocess_image(image):\n",
    "    sketch_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                      # NumPy → PIL\n",
    "    transforms.Grayscale(),                       # ensure 1 channel\n",
    "    transforms.Resize((28, 28)),                  # 28x28 like MNIST\n",
    "    transforms.Lambda(lambda img: ImageOps.invert(img)),  # invert colors\n",
    "    transforms.ToTensor(),                        # → tensor, shape (1,28,28), values in [0,1]\n",
    "    ])\n",
    "    # Gradio Sketchpad sometimes passes a dict with 'composite'\n",
    "    if isinstance(image, dict):\n",
    "        image = image['composite']   # this is a NumPy array\n",
    "    \n",
    "    # Apply the preprocessing transform\n",
    "    img_tensor = sketch_transform(image)  # (1, 28, 28)\n",
    "    \n",
    "    # Add batch dimension → (1, 1, 28, 28)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def predict_digit(image):\n",
    "    # --- STEP 1: CHECK IF SOMETHING HAS BEEN DRAWN ---\n",
    "    if image is None: return \"Draw something!\"\n",
    "\n",
    "    # --- STEP 2: PREPROCESS THE IMAGE ---\n",
    "    img_tensor = preprocess_image(image)\n",
    "    \n",
    "    # --- STEP 3: RUN THE MODEL ---\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img_tensor)\n",
    "        \n",
    "        # Get the index of the highest score (the predicted digit)\n",
    "        predicted_digit = torch.argmax(prediction).item()\n",
    "        \n",
    "    return str(predicted_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "257bc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "606eb64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=predict_digit,\n",
    "    inputs=gr.Sketchpad(type=\"numpy\", label=\"Draw a digit\"),\n",
    "    outputs=gr.Label(num_top_classes=1),\n",
    "    live=False\n",
    ")\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
